{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21867b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì° Scraping GitHub Trending en cours...\n",
      "üì¶ 132 projets collect√©s.\n",
      "‚úÖ Fichier veille enregistr√© : veille_github_2025-07.csv\n",
      "üîÅ Fichier connaissances_perso.csv mis √† jour avec 131 nouveaux outils.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# üîÅ Charger ton fichier connaissances_perso.csv\n",
    "def charger_connaissances_perso(fichier=\"connaissances_perso.csv\"):\n",
    "    try:\n",
    "        connaissances = pd.read_csv(fichier)\n",
    "    except FileNotFoundError:\n",
    "        # S'il n'existe pas, on cr√©e un fichier vide avec les colonnes attendues\n",
    "        colonnes = [\"Langage\", \"Nom\", \"Type\", \"Description\", \"√âtoiles\",\n",
    "                    \"Connu\", \"Ma√Ætrise\", \"Priorit√©_apprentissage\", \"Objectif_personnel\"]\n",
    "        connaissances = pd.DataFrame(columns=colonnes)\n",
    "        connaissances.to_csv(fichier, index=False)\n",
    "    return connaissances.fillna(\"\")\n",
    "\n",
    "\n",
    "# üß† Marquer chaque projet en fonction de tes connaissances\n",
    "def enrichir_resultats_avec_priorisation(resultats, connaissances_df):\n",
    "    nouveaux_resultats = []\n",
    "    for res in resultats:\n",
    "        nom = res[\"Nom\"].lower()\n",
    "        ligne = connaissances_df[connaissances_df[\"Nom\"].str.lower() == nom]\n",
    "        if not ligne.empty:\n",
    "            res[\"D√©j√†_connu\"] = ligne.iloc[0][\"Connu\"]\n",
    "            res[\"Ma√Ætrise\"] = ligne.iloc[0][\"Ma√Ætrise\"]\n",
    "            res[\"√Ä_travailler\"] = ligne.iloc[0][\"Priorit√©_apprentissage\"]\n",
    "            res[\"Objectif_personnel\"] = ligne.iloc[0][\"Objectif_personnel\"]\n",
    "        else:\n",
    "            res[\"D√©j√†_connu\"] = \"non\"\n",
    "            res[\"Ma√Ætrise\"] = \"non\"\n",
    "            res[\"√Ä_travailler\"] = \"oui\"\n",
    "            res[\"Objectif_personnel\"] = \"D√©couvrir\"\n",
    "        nouveaux_resultats.append(res)\n",
    "    return nouveaux_resultats\n",
    "\n",
    "\n",
    "# üéØ Classer automatiquement par type (Web, API‚Ä¶)\n",
    "def classify_type(description):\n",
    "    if not description:\n",
    "        return \"Autre\"\n",
    "    desc = description.lower()\n",
    "    keywords = {\n",
    "        \"Web\": [\"web\", \"browser\", \"html\", \"css\", \"javascript\", \"frontend\", \"site\", \"framework\"],\n",
    "        \"API\": [\"api\", \"rest\", \"endpoint\", \"client\", \"server\", \"proxy\", \"gateway\"],\n",
    "        \"NLP\": [\"language model\", \"llm\", \"nlp\", \"bert\", \"gpt\", \"transformer\", \"text\", \"token\", \"question answering\", \"summarization\"],\n",
    "        \"Data\": [\"data\", \"dataset\", \"dataframe\", \"database\", \"etl\", \"csv\", \"analytics\", \"visualization\", \"chart\", \"parquet\"],\n",
    "        \"ML\": [\"machine learning\", \"ml\", \"deep learning\", \"ai\", \"neural\", \"learning\", \"trainer\", \"classifier\", \"model\", \"inference\"]\n",
    "    }\n",
    "    for t, kwds in keywords.items():\n",
    "        if any(k in desc for k in kwds):\n",
    "            return t\n",
    "    return \"Autre\"\n",
    "\n",
    "\n",
    "# üì§ Scraping GitHub Trending\n",
    "def scrape_github_trending(language=\"python\"):\n",
    "    url = f\"https://github.com/trending/{language}?since=daily\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    projects = []\n",
    "\n",
    "    for repo in soup.find_all('article', class_='Box-row')[:50]:\n",
    "        try:\n",
    "            repo_name = repo.h2.a.text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "            owner, name = repo_name.split('/') if '/' in repo_name else (\"N/A\", repo_name)\n",
    "            desc_tag = repo.find('p', class_='col-9 color-fg-muted my-1 pr-4')\n",
    "            description = desc_tag.text.strip() if desc_tag else \"Pas de description\"\n",
    "            type_col = classify_type(description)\n",
    "            stars_tag = repo.find('span', class_='d-inline-block float-sm-right')\n",
    "            stars_text = stars_tag.text.strip() if stars_tag else \"0\"\n",
    "            stars_number = ''.join(c for c in stars_text if c.isdigit())\n",
    "\n",
    "            projects.append({\n",
    "                'Langage': language,\n",
    "                'Nom': name,\n",
    "                'Description': description,\n",
    "                '√âtoiles': stars_number,\n",
    "                'Type': type_col\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Erreur dans le parsing d‚Äôun d√©p√¥t :\", e)\n",
    "    return projects\n",
    "\n",
    "\n",
    "# üîÅ Mise √† jour automatique du fichier connaissances_perso.csv\n",
    "def mettre_a_jour_connaissances_perso(nouveaux_resultats, fichier=\"connaissances_perso.csv\"):\n",
    "    anciens = charger_connaissances_perso(fichier)\n",
    "    nouveaux = pd.DataFrame(nouveaux_resultats)\n",
    "    if not nouveaux.empty:\n",
    "        base = nouveaux[[\"Langage\", \"Nom\", \"Type\", \"Description\", \"√âtoiles\"]].copy()\n",
    "        base[\"Connu\"] = \"\"\n",
    "        base[\"Ma√Ætrise\"] = \"\"\n",
    "        base[\"Priorit√©_apprentissage\"] = \"\"\n",
    "        base[\"Objectif_personnel\"] = \"\"\n",
    "        fusion = pd.concat([anciens, base], ignore_index=True)\n",
    "        fusion = fusion.drop_duplicates(subset=['Nom'], keep='first')\n",
    "        fusion.to_csv(fichier, index=False)\n",
    "        print(f\"üîÅ Fichier {fichier} mis √† jour avec {len(fusion) - len(anciens)} nouveaux outils.\")\n",
    "    else:\n",
    "        print(\"Aucun outil √† ajouter √† la base de connaissances.\")\n",
    "\n",
    "\n",
    "# üöÄ G√©n√©ration de la veille + mise √† jour connaissances\n",
    "def generate_veille_github():\n",
    "    date_str = datetime.date.today().strftime(\"%Y-%m\")\n",
    "    filename = f\"veille_github_{date_str}.csv\"\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    topics = {\n",
    "        \"python\": \"Python\",\n",
    "        \"javascript\": \"JavaScript\",\n",
    "        \"rust\": \"Rust\",\n",
    "        \"go\": \"Go\",\n",
    "        \"typescript\": \"TypeScript\",\n",
    "        \"java\": \"Java\",\n",
    "        \"jupyter-notebook\": \"Jupyter\",\n",
    "        \"machine-learning\": \"Machine Learning\",\n",
    "        \"deep-learning\": \"Deep Learning\",\n",
    "    }\n",
    "\n",
    "    print(\"üì° Scraping GitHub Trending en cours...\")\n",
    "\n",
    "    for key, label in topics.items():\n",
    "        projets = scrape_github_trending(key)\n",
    "        for p in projets:\n",
    "            p[\"Langage\"] = label\n",
    "            p[\"Date\"] = date_str\n",
    "            all_results.append(p)\n",
    "\n",
    "    print(f\"üì¶ {len(all_results)} projets collect√©s.\")\n",
    "\n",
    "    # Charger les connaissances\n",
    "    connaissances_df = charger_connaissances_perso()\n",
    "\n",
    "    # Enrichir les r√©sultats\n",
    "    enriched = enrichir_resultats_avec_priorisation(all_results, connaissances_df)\n",
    "\n",
    "    # Enregistrer le fichier de veille du mois\n",
    "    fieldnames = [\n",
    "        \"Langage\", \"Nom\", \"Type\", \"D√©j√†_connu\", \"Ma√Ætrise\",\n",
    "        \"√Ä_travailler\", \"Objectif_personnel\", \"√âtoiles\", \"Date\", \"Description\"\n",
    "    ]\n",
    "\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in enriched:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"‚úÖ Fichier veille enregistr√© : {filename}\")\n",
    "\n",
    "    # Mise √† jour connaissances_perso.csv\n",
    "    mettre_a_jour_connaissances_perso(all_results)\n",
    "\n",
    "\n",
    "# ‚ñ∂Ô∏è Lancer tout automatiquement\n",
    "if __name__ == \"__main__\":\n",
    "    generate_veille_github()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41c5c736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier veille mensuelle : veille_data_2025-07.csv\n",
      "üîÅ Fichier connaissances_data.csv mis √† jour.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Charger le fichier comp√©tences perso ou cr√©er un vide\n",
    "def charger_connaissances_data(fichier='connaissances_data.csv'):\n",
    "    try:\n",
    "        df = pd.read_csv(fichier)\n",
    "    except FileNotFoundError:\n",
    "        colonnes = [\"Langage\", \"Nom\", \"Type\", \"D√©j√†_connu\", \"Ma√Ætrise\", \"√Ä_travailler\", \"Objectif_personnel\", \"√âtoiles\", \"Date\", \"Description\"]\n",
    "        df = pd.DataFrame(columns=colonnes)\n",
    "        df.to_csv(fichier, index=False)\n",
    "    return df.fillna(\"\")\n",
    "\n",
    "# Classifier Data Science/DataViz/ML/NLP en fonction de la description\n",
    "def classify_type(description):\n",
    "    if not description:\n",
    "        return \"Autre\"\n",
    "    desc = description.lower()\n",
    "    keywords = {\n",
    "        \"Data\": [\"data\", \"dataset\", \"dataframe\", \"etl\", \"csv\", \"parquet\", \"panda\", \"dplyr\", \"tidyverse\"],\n",
    "        \"DataViz\": [\"visualization\", \"viz\", \"plot\", \"matplotlib\", \"seaborn\", \"chart\", \"graph\", \"bokeh\", \"plotly\"],\n",
    "        \"ML\": [\"machine learning\", \"ml\", \"deep learning\", \"ai\", \"neural\", \"regression\", \"classification\", \"feature\", \"predict\"],\n",
    "        \"NLP\": [\"nlp\", \"text\", \"language\", \"bert\", \"llm\", \"transformer\", \"gpt\", \"token\", \"embedding\"],\n",
    "    }\n",
    "    for t, kwds in keywords.items():\n",
    "        if any(k in desc for k in kwds):\n",
    "            return t\n",
    "    return \"Autre\"\n",
    "\n",
    "# Scraper GitHub Trending pour langages Data Science\n",
    "def scrape_github_trending(language=\"python\"):\n",
    "    url = f\"https://github.com/trending/{language}?since=daily\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    projects = []\n",
    "    for repo in soup.find_all('article', class_='Box-row')[:50]:\n",
    "        try:\n",
    "            repo_name = repo.h2.a.text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "            owner, name = repo_name.split('/') if '/' in repo_name else (\"N/A\", repo_name)\n",
    "            desc_tag = repo.find('p', class_='col-9 color-fg-muted my-1 pr-4')\n",
    "            description = desc_tag.text.strip() if desc_tag else \"Pas de description\"\n",
    "            type_col = classify_type(description)\n",
    "            stars_tag = repo.find('span', class_='d-inline-block float-sm-right')\n",
    "            stars_text = stars_tag.text.strip() if stars_tag else \"0\"\n",
    "            stars_number = ''.join(c for c in stars_text if c.isdigit())\n",
    "            projects.append({\n",
    "                'Langage': language,\n",
    "                'Nom': name,\n",
    "                'Description': description,\n",
    "                '√âtoiles': stars_number,\n",
    "                'Type': type_col\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(\"Erreur d√©p√¥t :\", e)\n",
    "    return projects\n",
    "\n",
    "# Enrichir avec comp√©tences perso\n",
    "def enrichir_resultats_avec_priorisation(resultats, connaissances_df, date_str):\n",
    "    nouveaux_resultats = []\n",
    "    for res in resultats:\n",
    "        nom = res[\"Nom\"].lower()\n",
    "        ligne = connaissances_df[connaissances_df[\"Nom\"].str.lower() == nom]\n",
    "        res[\"Date\"] = date_str\n",
    "        if not ligne.empty:\n",
    "            res[\"D√©j√†_connu\"] = ligne.iloc[0][\"D√©j√†_connu\"]\n",
    "            res[\"Ma√Ætrise\"] = ligne.iloc[0][\"Ma√Ætrise\"]\n",
    "            res[\"√Ä_travailler\"] = ligne.iloc[0][\"√Ä_travailler\"]\n",
    "            res[\"Objectif_personnel\"] = ligne.iloc[0][\"Objectif_personnel\"]\n",
    "        else:\n",
    "            res[\"D√©j√†_connu\"] = \"\"\n",
    "            res[\"Ma√Ætrise\"] = \"\"\n",
    "            res[\"√Ä_travailler\"] = \"oui\"\n",
    "            res[\"Objectif_personnel\"] = \"\"\n",
    "        nouveaux_resultats.append(res)\n",
    "    return nouveaux_resultats\n",
    "\n",
    "# Mettre √† jour automatiquement le r√©f√©rentiel\n",
    "def mettre_a_jour_connaissances_data(nouveaux_resultats, fichier=\"connaissances_data.csv\"):\n",
    "    colonnes = [\n",
    "        \"Langage\", \"Nom\", \"Type\", \"D√©j√†_connu\", \"Ma√Ætrise\", \"√Ä_travailler\",\n",
    "        \"Objectif_personnel\", \"√âtoiles\", \"Date\", \"Description\"\n",
    "    ]\n",
    "    try:\n",
    "        ancien_df = pd.read_csv(fichier)\n",
    "    except FileNotFoundError:\n",
    "        ancien_df = pd.DataFrame(columns=colonnes)\n",
    "    nouveaux_df = pd.DataFrame(nouveaux_resultats)\n",
    "    for col in colonnes:\n",
    "        if col not in nouveaux_df.columns:\n",
    "            nouveaux_df[col] = \"\"\n",
    "    nouveaux_df = nouveaux_df[colonnes]\n",
    "    fusion_df = pd.concat([ancien_df, nouveaux_df], ignore_index=True)\n",
    "    fusion_df = fusion_df.drop_duplicates(subset=[\"Nom\"], keep=\"first\")\n",
    "    fusion_df.to_csv(fichier, index=False)\n",
    "    print(f\"üîÅ Fichier {fichier} mis √† jour.\")\n",
    "\n",
    "# Fonction principale\n",
    "def automatique_veille_data():\n",
    "    date_str = datetime.date.today().strftime(\"%Y-%m\")\n",
    "    filename = f\"veille_data_{date_str}.csv\"\n",
    "    all_results = []\n",
    "    topics = {\n",
    "        \"python\": \"Python\",\n",
    "        \"r\": \"R\",\n",
    "        \"julia\": \"Julia\",\n",
    "        \"jupyter-notebook\": \"Jupyter\",\n",
    "    }\n",
    "    for key, label in topics.items():\n",
    "        projets = scrape_github_trending(key)\n",
    "        for p in projets:\n",
    "            p[\"Langage\"] = label\n",
    "            all_results.append(p)\n",
    "    connaissances_df = charger_connaissances_data()\n",
    "    enriched = enrichir_resultats_avec_priorisation(all_results, connaissances_df, date_str)\n",
    "    # G√©n√©rer le CSV du mois\n",
    "    fieldnames = [\n",
    "        \"Langage\", \"Nom\", \"Type\", \"D√©j√†_connu\", \"Ma√Ætrise\", \"√Ä_travailler\",\n",
    "        \"Objectif_personnel\", \"√âtoiles\", \"Date\", \"Description\"\n",
    "    ]\n",
    "    with open(filename, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in enriched:\n",
    "            writer.writerow(row)\n",
    "    print(f\"‚úÖ Fichier veille mensuelle : {filename}\")\n",
    "    mettre_a_jour_connaissances_data(enriched)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    automatique_veille_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basedata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
